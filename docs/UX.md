# 音声品質改善エージェント・スタック: LOOP

## 1. はじめに
本ドキュメントは、TTS (Text-to-Speech) 生成音声の品質を自動的に診断し、その「違和感」を数値化・分類することで、改善アクションを提案するエージェント・スタック「LOOP」の設計と実装について記述します。このシステムは、生成された音声の品質問題を特定し、LoRA (Low-Rank Adaptation) の適用判断を含む具体的な改善策を提示することを目的としています。

## 2. エージェント・ループのアーキテクチャ
LOOPは、以下の4つの主要なエージェントで構成される反復的なプロセス（ループ）を通じて、音声品質の改善を推進します。各エージェントは特定の役割を担い、情報を連携しながら最終的な診断レポートと改善提案を生成します。

| エージェント名 | 役割 | 入力 | 出力 |
| :--- | :--- | :--- | :--- |
| **Inspector (検査官)** | 音声波形から物理的・音響的特徴量を抽出します。音質、ピッチ、無音区間などの低レベルな特徴を分析します。 | 音声ファイル (WAV) | 診断生データ (F0, SNR, スペクトル平坦度, クリッピング率など) |
| **Linguist (言語学者)** | 入力テキストとASR (自動音声認識) 結果を比較し、発音の正確性や音素のアライメントを評価します。 | 音声ファイル (WAV), 入力テキスト | WER/CER (単語/文字誤り率), 音素持続時間, 誤読箇所 |
| **Diagnostician (診断医)** | InspectorとLinguistから得られたデータを統合し、音声の違和感の原因を「音質」「発音」「抑揚/間」の3つのカテゴリに分類してスコアリングします。 | 検査官 & 言語学者のデータ | 統合診断レポート (JSON形式) |
| **Strategist (戦略家)** | 診断医のレポートに基づき、TTS生成パラメータの調整、フロントエンドの修正、またはLoRAによるモデル改善といった具体的な修正アクションを提案します。 | 統合診断レポート | 改善提案 (テキスト形式) |

### 2.1. 改善ループのフロー
1. **Generate (生成):** TTSモデルを用いて音声を生成します。
2. **Analyze (分析):** 生成された音声に対し、InspectorとLinguistが並行して分析を実行します。
3. **Diagnose (診断):** Diagnosticianが分析結果を統合し、音声品質の問題点を特定します。
4. **Strategize (戦略立案):** Strategistが診断結果に基づき、最も効果的な改善策を立案します。
5. **Act (実行):** 立案された戦略に基づき、TTSモデルのパラメータ調整、G2P辞書の更新、またはLoRAを用いたモデルの再学習といったアクションを実行します。このプロセスは、品質が許容レベルに達するまで繰り返されます。

## 3. 診断指標の詳細
各エージェントが利用する主要な診断指標は以下の通りです。

### 3.1. Quality (音質)
- **Clipping Rate:** 音声信号が最大振幅を超過する割合。高い場合は音割れを示唆します。
- **SNR (Signal-to-Noise Ratio) Estimation:** 信号とノイズの比率。ノイズが多い環境での生成や、ボコーダの品質問題を示唆します。
- **Spectral Flatness:** スペクトルの平坦度。値が高いほどノイズ的、低いほど調波的（音楽的）な特性を持ちます。金属音やざらつきの検出に利用されます。
- **MOS (Mean Opinion Score) Prediction (非参照型):** 音声の自然さや品質を人間の聴覚評価に近い形で推定するスコア。本システムでは、既存のMOS予測モデルの統合を想定しています。

### 3.2. Pronunciation (発音)
- **CER (Character Error Rate) / WER (Word Error Rate):** 入力テキストとASR結果を比較し、文字または単語レベルでの誤り率を算出します。高い場合は、TTSモデルの発音能力、G2P (Grapheme-to-Phoneme) 変換、またはアクセント辞書の問題を示唆します。
- **Confidence Score (ASR):** ASRモデルが各単語や音素に対して出力する確信度。低い確信度の箇所は、発音の不明瞭さや曖昧さを示唆します。

### 3.3. Prosody (抑揚/間)
- **F0 (Fundamental Frequency) Range:** ピッチの変動範囲。狭すぎる場合は棒読み、広すぎる場合は不自然な抑揚を示唆します。
- **F0 Jump / Discontinuity:** ピッチの急激な変化。不自然な音の飛びや途切れを示唆します。
- **Phone Duration Z-score (Forced Alignment):** 強制アライメントによって得られた音素持続時間と、標準的な持続時間との乖離。不自然な伸びや詰まり、リズムの崩れを検出します。
- **Silence Distribution:** 無音区間の長さと配置。不自然な「間」や、句読点と音声の間隔の不一致を検出します。

## 4. 実装の概要
本システムはPythonで実装されており、`librosa`や`numpy`といった音声処理ライブラリを活用します。ASRやMOS予測には、既存の高性能なモデル（例: Whisper for ASR, 非参照型MOS予測器）を統合することを想定しています。

### 4.1. `inspector.py`
`inspector.py`は、音声ファイルから以下の特徴量を抽出します。
- クリッピング率
- 簡易SNR推定
- スペクトル平坦度
- F0の統計量 (平均、標準偏差、範囲、最大ジャンプ)
- 無音区間の持続時間

### 4.2. `diagnostician.py`
`diagnostician.py`は、`inspector.py`からの出力と、Linguistからのモックデータ（CERなど）を受け取り、以下のロジックに基づいて診断レポートを生成します。
- **スコアリング:** 各カテゴリ (Quality, Pronunciation, Prosody) に対して0-100のスコアを付与します。
- **ハイライト:** 特定の閾値を超えた問題点をテキストで記述します。
- **改善提案:** 問題点に応じた具体的な修正アクションを提案します。
- **LoRA推奨:** 全体スコアや特定のカテゴリのスコアが低い場合に、LoRAによる追加学習を推奨します。

### 4.3. `loop_manager.py`
`loop_manager.py`は、エージェント・ループ全体のオーケストレーションを担います。音声ファイルのパスを受け取り、`inspector.py`と`diagnostician.py`を順次実行し、最終的な診断レポートを生成します。Linguistエージェントは、現状ではモックデータを使用していますが、将来的にはASRモデルとの連携を想定しています。

## 5. 今後の展望
- **Linguistエージェントの本格実装:** WhisperなどのASRモデルとForced Alignmentツールを統合し、より詳細な発音・アライメント分析を可能にします。
- **MOS予測モデルの統合:** 非参照型MOS予測モデルを組み込み、より客観的な音質評価を実現します。
- **Strategistエージェントの強化:** TTSモデルの内部パラメータやG2P辞書、アクセント辞書との連携を深め、より精度の高い自動改善提案を可能にします。
- **GUI/可視化インターフェース:** 診断結果や改善履歴を視覚的に表示するインターフェースを開発し、ユーザーエクスペリエンスを向上させます。

## 6. 参考文献
[1] Librosa: Audio and music analysis in Python. [https://librosa.org/](https://librosa.org/)
[2] NumPy: The fundamental package for scientific computing with Python. [https://numpy.org/](https://numpy.org/)
# LoRA作成エラー修正レポート

## 1. 発生していた問題
`rora.ipynb` の実行時に以下のエラーが発生していました。

- **ModuleNotFoundError: No module named 'safetensors.torch'**
  - `transformers` や `peft` ライブラリが内部で使用している `safetensors` がインストールされていなかったためです。
- **AttributeError: 'NoneType' object has no attribute '__dict__'**
  - `base_model` が `None` のまま `get_peft_model` に渡されていたためです。

## 2. 実施した修正内容
1.  **依存関係の解消**:
    - `safetensors`, `peft`, `datasets`, `transformers`, `torch` を環境にインストールしました。
2.  **PoCスクリプトの作成 (`lora_poc.py`)**:
    - 軽量モデル（`tiny-gpt2`）を使用して、LoRAモデルが正しく初期化・動作することを確認しました。
3.  **修正版ノートブックの作成 (`rora_fixed.ipynb`)**:
    - 環境構築用のセルを追加しました。
    - モデルのロード部分に具体的なコード例を追加し、`base_model` が `None` にならないようにしました。

## 3. 今後の手順
LoRA学習を本格的に進めるためには、以下の手順が必要です。

1.  **音声モデルの選定**:
    - XTTS-v2 や VITS など、ファインチューニング対象のモデルを `base_model` としてロードしてください。
2.  **データセットの準備**:
    - 志ん生の音声データとテキストのペアを `datasets` ライブラリで読み込める形式に整理してください。
3.  **GPU環境での実行**:
    - 本格的な学習には GPU (VRAM 16GB以上推奨) が必要です。

修正済みの `rora_fixed.ipynb` をベースに進めてみてください。
