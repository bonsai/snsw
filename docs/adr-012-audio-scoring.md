# ADR-012: 音声品質の自動採点システムの導入

## 1. ステータス
**承認済み**

## 2. コンテキスト
複数のTTSモデル（XTTS, GPT-SoVITS, Fish-Speech等）を使用して生成された音声の品質を、客観的かつ定量的に評価する必要がある。物理的な統計情報（RMS等）に加え、「人間にとっての自然さ」や「話者の再現度」を測るAIモデルによる採点を導入する。

## 3. 決定事項
AIモデルを使用してWAVファイルを採点する仕組みを導入する。評価軸として以下の3点を中心にスコアリングを行う。

### 1. MOS (Mean Opinion Score) 予測
- **手法**: NISQAやWav2Vec 2.0ベースの評価モデルを使用。
- **目的**: 人間が感じる「自然さ」を1.0〜5.0でスコアリングする。

### 2. 話者類似度 (Speaker Similarity)
- **手法**: ResemblyzerやECAPA-TDNNを使用。
- **目的**: 参照音声（SOURCE/001.wav等）と生成音声のコサイン類似度を算出する。

### 3. 明瞭度 (Intelligibility/WER)
- **手法**: Whisper等のASRモデルで文字起こしを行い、テキスト一致率を算出。
- **目的**: 発話内容の正確性を担保する。

## 4. 物理統計情報との統合
平均振幅、最大振幅、RMSなどの既存の物理特性も引き続き取得し、AIスコアと合わせて総合レポートを出力する。

## 5. 結果
- モデル間の品質差を数値で比較可能になる。
- 物理的な音量バランスだけでなく、聴感上の品質を担保できる。
- 自動評価ループを回すことで、最適なハイパーパラメータの探索が容易になる。
