{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qwen2-Audio + Qwen-TTS ãƒœã‚¤ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ³ POC\n",
    "## Qwenå°‚ç”¨ã®æœ€å°æ§‹æˆãƒœã‚¤ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ³ã‚·ã‚¹ãƒ†ãƒ \n",
    "\n",
    "**ç‰¹å¾´:**\n",
    "- Qwen2-Audioï¼ˆéŸ³å£°èªè­˜ + è©±è€…ç‰¹å¾´æŠ½å‡ºï¼‰\n",
    "- Qwen-TTSï¼ˆã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆéŸ³å£°åˆæˆï¼‰\n",
    "- 5-30ç§’ã®å‚ç…§éŸ³å£°ã§ã‚¯ãƒ­ãƒ¼ãƒ³å¯èƒ½\n",
    "- æ—¥æœ¬èªæœ€é©åŒ–"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n",
    "# Qwen2-Audio: éŸ³å£°èªè­˜ã¨è©±è€…ç‰¹å¾´æŠ½å‡º\n",
    "# transformers: Hugging Faceãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰\n",
    "# librosa: éŸ³å£°å‡¦ç†\n",
    "# soundfile: WAVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿æ›¸ã\n",
    "!pip install -q torch torchaudio transformers librosa soundfile accelerate\n",
    "!pip install -q git+https://github.com/QwenLM/Qwen-Audio.git\n",
    "\n",
    "print(\"âœ“ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«å®Œäº†\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ\n",
    "import torch\n",
    "import torchaudio\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "from IPython.display import Audio, display\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# GPU/CPUè¨­å®š\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"âœ“ ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹: {device}\")\n",
    "print(f\"âœ“ PyTorch version: {torch.__version__}\")\n",
    "print(f\"âœ“ CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ\n",
    "output_dir = Path(\"outputs\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "print(f\"âœ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Qwen2-Audio ASRãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰\n",
    "éŸ³å£°èªè­˜ã¨è©±è€…ç‰¹å¾´æŠ½å‡ºã‚’è¡Œã†ãƒ¢ãƒ‡ãƒ«"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qwen2-Audioãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰\n",
    "# ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯éŸ³å£°èªè­˜ï¼ˆASRï¼‰ã¨è©±è€…ç‰¹å¾´æŠ½å‡ºã®ä¸¡æ–¹ã‚’è¡Œã†\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«IDï¼ˆ7Bãƒ¢ãƒ‡ãƒ«: é«˜å“è³ªã ãŒVRAM 8-12GBå¿…è¦ï¼‰\n",
    "asr_model_id = \"Qwen/Qwen2-Audio-7B-Instruct\"\n",
    "\n",
    "print(f\"Qwen2-Audioãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­: {asr_model_id}\")\n",
    "print(\"â€» åˆå›ã¯æ•°åˆ†ã‹ã‹ã‚Šã¾ã™ï¼ˆãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚º: ç´„14GBï¼‰\")\n",
    "\n",
    "# ãƒ—ãƒ­ã‚»ãƒƒã‚µã®ãƒ­ãƒ¼ãƒ‰ï¼ˆéŸ³å£°ã®å‰å‡¦ç†ã‚’æ‹…å½“ï¼‰\n",
    "asr_processor = AutoProcessor.from_pretrained(asr_model_id)\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰\n",
    "# load_in_8bit=True ã§VRAMä½¿ç”¨é‡ã‚’å‰Šæ¸›å¯èƒ½ï¼ˆå“è³ªã¯è‹¥å¹²ä½ä¸‹ï¼‰\n",
    "asr_model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    asr_model_id,\n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "    device_map=\"auto\",\n",
    "    # load_in_8bit=True,  # VRAMä¸è¶³ã®å ´åˆã¯ã‚³ãƒ¡ãƒ³ãƒˆè§£é™¤\n",
    ")\n",
    "\n",
    "print(\"âœ“ Qwen2-Audioãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰å®Œäº†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. å‚ç…§éŸ³å£°ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "5-30ç§’ç¨‹åº¦ã®ã‚¯ãƒªã‚¢ãªéŸ³å£°ã‚’æ¨å¥¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å‚ç…§éŸ³å£°ã®èª­ã¿è¾¼ã¿\n",
    "# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§001.wavã‚’æ¢ã—ã€ãªã‘ã‚Œã°ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚’ä¿ƒã™\n",
    "import os\n",
    "\n",
    "# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®å‚ç…§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å\n",
    "default_audio_file = \"001.wav\"\n",
    "\n",
    "# 001.wavãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯\n",
    "if os.path.exists(default_audio_file):\n",
    "    # 001.wavãŒè¦‹ã¤ã‹ã£ãŸå ´åˆ\n",
    "    ref_audio_path = default_audio_file\n",
    "    print(f\"âœ“ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡º: {ref_audio_path}\")\n",
    "else:\n",
    "    # 001.wavãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã€ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚’ä¿ƒã™\n",
    "    print(f\"âš ï¸ ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ« '{default_audio_file}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "    print(\"\\nå‚ç…§éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„\")\n",
    "    print(\"æ¨å¥¨: 5-30ç§’ã€ã‚¯ãƒªã‚¢ãªéŸ³è³ªã€ãƒã‚¤ã‚ºãªã—ã€WAV/MP3å½¢å¼\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    try:\n",
    "        # Google Colabç’°å¢ƒã§ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "        from google.colab import files\n",
    "        uploaded = files.upload()\n",
    "        \n",
    "        if len(uploaded) == 0:\n",
    "            raise ValueError(\"ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ\")\n",
    "        \n",
    "        ref_audio_path = list(uploaded.keys())[0]\n",
    "        print(f\"\\nâœ“ ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å®Œäº†: {ref_audio_path}\")\n",
    "        \n",
    "    except ImportError:\n",
    "        # ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã®å ´åˆ\n",
    "        print(\"\\nâš ï¸ Google Colabç’°å¢ƒã§ã¯ã‚ã‚Šã¾ã›ã‚“\")\n",
    "        print(\"ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§ã¯ã€001.wavãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¨åŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«é…ç½®ã—ã¦ãã ã•ã„\")\n",
    "        raise FileNotFoundError(f\"'{default_audio_file}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\")\n",
    "\n",
    "# éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã¨æƒ…å ±è¡¨ç¤º\n",
    "print(f\"\\nğŸ“‚ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­: {ref_audio_path}\")\n",
    "ref_audio, ref_sr = librosa.load(ref_audio_path, sr=16000, mono=True)\n",
    "ref_duration = len(ref_audio) / ref_sr\n",
    "\n",
    "print(f\"\\n--- å‚ç…§éŸ³å£°æƒ…å ± ---\")\n",
    "print(f\"ãƒ•ã‚¡ã‚¤ãƒ«å: {ref_audio_path}\")\n",
    "print(f\"é•·ã•: {ref_duration:.2f}ç§’\")\n",
    "print(f\"ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ: {ref_sr}Hz\")\n",
    "print(f\"ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(ref_audio):,}\")\n",
    "\n",
    "# éŸ³å£°ã®é•·ã•ãƒã‚§ãƒƒã‚¯\n",
    "if ref_duration < 3:\n",
    "    print(f\"âš ï¸ è­¦å‘Š: éŸ³å£°ãŒçŸ­ã™ãã¾ã™ï¼ˆ{ref_duration:.1f}ç§’ï¼‰ã€‚5ç§’ä»¥ä¸Šã‚’æ¨å¥¨ã—ã¾ã™ã€‚\")\n",
    "elif ref_duration > 30:\n",
    "    print(f\"âš ï¸ è­¦å‘Š: éŸ³å£°ãŒé•·ã™ãã¾ã™ï¼ˆ{ref_duration:.1f}ç§’ï¼‰ã€‚30ç§’ä»¥ä¸‹ã‚’æ¨å¥¨ã—ã¾ã™ã€‚\")\n",
    "else:\n",
    "    print(f\"âœ“ éŸ³å£°ã®é•·ã•ã¯é©åˆ‡ã§ã™\")\n",
    "\n",
    "# éŸ³å£°ã®å†ç”Ÿ\n",
    "print(\"\\nğŸ”Š å‚ç…§éŸ³å£°ã‚’å†ç”Ÿ:\")\n",
    "display(Audio(ref_audio, rate=ref_sr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Qwen2-Audioã§éŸ³å£°èªè­˜ã¨è©±è€…ç‰¹å¾´æŠ½å‡º\n",
    "å‚ç…§éŸ³å£°ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã¨è©±è€…ã®å£°è³ªæƒ…å ±ã‚’å–å¾—"
   ]
  },
   "outputs": [],
   "source": [
    "# éŸ³å£°èªè­˜ï¼ˆASRï¼‰ã®å®Ÿè¡Œ\n",
    "# Qwen2-Audioã¯éŸ³å£°ã‚’èã„ã¦ã€è©±ã•ã‚Œã¦ã„ã‚‹å†…å®¹ã‚’ãƒ†ã‚­ã‚¹ãƒˆåŒ–ã™ã‚‹\n",
    "print(\"ğŸ™ï¸ éŸ³å£°èªè­˜ã‚’å®Ÿè¡Œä¸­...\")\n",
    "\n",
    "# éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†\n",
    "# ãƒ—ãƒ­ã‚»ãƒƒã‚µãŒéŸ³å£°ã‚’ãƒ¢ãƒ‡ãƒ«ãŒç†è§£ã§ãã‚‹å½¢å¼ã«å¤‰æ›\n",
    "inputs = asr_processor(\n",
    "    ref_audio,\n",
    "    sampling_rate=ref_sr,\n",
    "    return_tensors=\"pt\"\n",
    ").to(device)\n",
    "\n",
    "# éŸ³å£°èªè­˜ã®å®Ÿè¡Œ\n",
    "# generate()ãƒ¡ã‚½ãƒƒãƒ‰ã§ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆ\n",
    "with torch.no_grad():\n",
    "    generated_ids = asr_model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=256,  # ç”Ÿæˆã™ã‚‹æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°\n",
    "    )\n",
    "\n",
    "# ç”Ÿæˆã•ã‚ŒãŸãƒˆãƒ¼ã‚¯ãƒ³IDã‚’ãƒ†ã‚­ã‚¹ãƒˆã«ãƒ‡ã‚³ãƒ¼ãƒ‰\n",
    "transcription = asr_processor.batch_decode(\n",
    "    generated_ids,\n",
    "    skip_special_tokens=True\n",
    ")[0]\n",
    "\n",
    "print(\"âœ“ éŸ³å£°èªè­˜å®Œäº†\")\n",
    "print(f\"\\n--- èªè­˜ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ ---\")\n",
    "print(transcription)\n",
    "\n",
    "# èªè­˜çµæœã‚’å¤‰æ•°ã«ä¿å­˜ï¼ˆå¾Œã§TTSã«ä½¿ç”¨ï¼‰\n",
    "ref_text = transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è©±è€…ç‰¹å¾´ï¼ˆSpeaker Embeddingï¼‰ã®æŠ½å‡º\n",
    "# Qwen2-Audioã®éš ã‚Œå±¤ã‹ã‚‰è©±è€…ã®å£°è³ªæƒ…å ±ã‚’å–å¾—\n",
    "print(\"ğŸ—£ï¸ è©±è€…ç‰¹å¾´ã‚’æŠ½å‡ºä¸­...\")\n",
    "\n",
    "# ãƒ¢ãƒ‡ãƒ«ã®éš ã‚Œå±¤å‡ºåŠ›ã‚’å–å¾—\n",
    "with torch.no_grad():\n",
    "    outputs = asr_model(\n",
    "        **inputs,\n",
    "        output_hidden_states=True,  # éš ã‚Œå±¤ã®å‡ºåŠ›ã‚’å–å¾—\n",
    "    )\n",
    "\n",
    "# æœ€çµ‚å±¤ã®éš ã‚ŒçŠ¶æ…‹ã‚’è©±è€…ç‰¹å¾´ã¨ã—ã¦ä½¿ç”¨\n",
    "# ã“ã‚ŒãŒè©±è€…ã®ã€Œå£°è³ªã€ã‚’è¡¨ç¾ã™ã‚‹ãƒ™ã‚¯ãƒˆãƒ«\n",
    "speaker_embedding = outputs.hidden_states[-1].mean(dim=1)  # æ™‚é–“è»¸ã§å¹³å‡åŒ–\n",
    "\n",
    "print(\"âœ“ è©±è€…ç‰¹å¾´ã®æŠ½å‡ºå®Œäº†\")\n",
    "print(f\"Speaker Embedding shape: {speaker_embedding.shape}\")\n",
    "print(f\"ã“ã‚ŒãŒè©±è€…ã®å£°è³ªã‚’è¡¨ç¾ã™ã‚‹ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«ã§ã™\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Qwen-TTSãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰\n",
    "éŸ³å£°åˆæˆï¼ˆText-to-Speechï¼‰ã‚’è¡Œã†ãƒ¢ãƒ‡ãƒ«"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qwen-TTSã¾ãŸã¯CosyVoiceã®ãƒ­ãƒ¼ãƒ‰\n",
    "# æ³¨: Qwen-TTSã®å…¬å¼å®Ÿè£…ãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆã¯ãã¡ã‚‰ã‚’ä½¿ç”¨\n",
    "# ã“ã“ã§ã¯CosyVoiceï¼ˆQwenäº’æ›ï¼‰ã‚’ä½¿ç”¨ã™ã‚‹ä¾‹ã‚’ç¤ºã—ã¾ã™\n",
    "\n",
    "try:\n",
    "    # CosyVoiceã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆQwenäº’æ›ã®TTSãƒ¢ãƒ‡ãƒ«ï¼‰\n",
    "    !pip install -q cosyvoice\n",
    "    from cosyvoice import CosyVoice\n",
    "    \n",
    "    print(\"CosyVoiceãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...\")\n",
    "    tts_model = CosyVoice.from_pretrained(\n",
    "        \"FunAudioLLM/CosyVoice-300M\",\n",
    "        device=device\n",
    "    )\n",
    "    print(\"âœ“ CosyVoiceãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰å®Œäº†\")\n",
    "    TTS_AVAILABLE = True\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ TTSãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—: {e}\")\n",
    "    print(\"ãƒ€ãƒŸãƒ¼ãƒ¢ãƒ¼ãƒ‰ã§ç¶™ç¶šã—ã¾ã™ï¼ˆå®Ÿéš›ã®éŸ³å£°ç”Ÿæˆã¯è¡Œã‚ã‚Œã¾ã›ã‚“ï¼‰\")\n",
    "    TTS_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ç”Ÿæˆã—ãŸã„ãƒ†ã‚­ã‚¹ãƒˆã®å…¥åŠ›"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# éŸ³å£°åˆæˆã—ãŸã„ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›\n",
    "# å‚ç…§éŸ³å£°ã®è©±è€…ã®å£°ã§ã€ã“ã®ãƒ†ã‚­ã‚¹ãƒˆãŒèª­ã¿ä¸Šã’ã‚‰ã‚Œã¾ã™\n",
    "target_texts = [\n",
    "    \"ã“ã‚“ã«ã¡ã¯ã€ä»Šæ—¥ã¯ã¨ã¦ã‚‚è‰¯ã„å¤©æ°—ã§ã™ã­ã€‚\",\n",
    "    \"å¯¿é™ç„¡ã€å¯¿é™ç„¡ã€äº”åŠ«ã®æ“¦ã‚Šåˆ‡ã‚Œã€‚\",\n",
    "    \"ã“ã‚Œã¯éŸ³å£°ã‚¯ãƒ­ãƒ¼ãƒ³æŠ€è¡“ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã™ã€‚\",\n",
    "]\n",
    "\n",
    "print(\"--- ç”Ÿæˆã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ ---\")\n",
    "for i, text in enumerate(target_texts, 1):\n",
    "    print(f\"{i}. {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. éŸ³å£°ç”Ÿæˆï¼ˆVoice Cloningï¼‰\n",
    "å‚ç…§éŸ³å£°ã®å£°è³ªã§æ–°ã—ã„ãƒ†ã‚­ã‚¹ãƒˆã‚’èª­ã¿ä¸Šã’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# éŸ³å£°ç”Ÿæˆã®å®Ÿè¡Œ\n",
    "if TTS_AVAILABLE:\n",
    "    print(\"ğŸµ éŸ³å£°ã‚’ç”Ÿæˆä¸­...\")\n",
    "    \n",
    "    generated_audios = []\n",
    "    \n",
    "    for i, text in enumerate(target_texts, 1):\n",
    "        print(f\"\\n[{i}/{len(target_texts)}] ç”Ÿæˆä¸­: {text[:30]}...\")\n",
    "        \n",
    "        # TTSãƒ¢ãƒ‡ãƒ«ã§éŸ³å£°ç”Ÿæˆ\n",
    "        # speaker_embeddingã‚’æ¡ä»¶ã¨ã—ã¦ä¸ãˆã‚‹ã“ã¨ã§ã€å‚ç…§éŸ³å£°ã®å£°è³ªã‚’å†ç¾\n",
    "        audio = tts_model.inference(\n",
    "            text=text,\n",
    "            speaker_embedding=speaker_embedding,  # è©±è€…ç‰¹å¾´ã‚’ä½¿ç”¨\n",
    "            language=\"ja\",  # æ—¥æœ¬èª\n",
    "        )\n",
    "        \n",
    "        generated_audios.append(audio)\n",
    "        print(f\"âœ“ ç”Ÿæˆå®Œäº†\")\n",
    "    \n",
    "    print(f\"\\nâœ“ ã™ã¹ã¦ã®éŸ³å£°ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼ˆ{len(generated_audios)}ä»¶ï¼‰\")\n",
    "    \n",
    "else:\n",
    "    print(\"âš ï¸ TTSãƒ¢ãƒ‡ãƒ«ãŒåˆ©ç”¨ã§ããªã„ãŸã‚ã€éŸ³å£°ç”Ÿæˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™\")\n",
    "    # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆï¼ˆãƒ‡ãƒ¢ç”¨ï¼‰\n",
    "    generated_audios = [np.zeros(16000) for _ in target_texts]\n",
    "    print(\"ãƒ€ãƒŸãƒ¼éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—ã¾ã—ãŸ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ç”ŸæˆéŸ³å£°ã®å†ç”Ÿã¨ä¿å­˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”Ÿæˆã•ã‚ŒãŸéŸ³å£°ã‚’å†ç”Ÿãƒ»ä¿å­˜\n",
    "sample_rate = 16000  # TTSãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ãƒ¬ãƒ¼ãƒˆ\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ç”ŸæˆéŸ³å£°ã®å†ç”Ÿã¨ä¿å­˜\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, (audio, text) in enumerate(zip(generated_audios, target_texts), 1):\n",
    "    print(f\"\\n--- éŸ³å£° {i} ---\")\n",
    "    print(f\"ãƒ†ã‚­ã‚¹ãƒˆ: {text}\")\n",
    "    \n",
    "    # éŸ³å£°ã®å†ç”Ÿ\n",
    "    print(\"ğŸ”Š å†ç”Ÿ:\")\n",
    "    display(Audio(audio, rate=sample_rate))\n",
    "    \n",
    "    # WAVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜\n",
    "    output_path = output_dir / f\"cloned_{i:03d}.wav\"\n",
    "    sf.write(output_path, audio, sample_rate)\n",
    "    print(f\"ğŸ’¾ ä¿å­˜: {output_path}\")\n",
    "\n",
    "print(f\"\\nâœ“ ã™ã¹ã¦ã®éŸ³å£°ã‚’ {output_dir}/ ã«ä¿å­˜ã—ã¾ã—ãŸ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”Ÿæˆæƒ…å ±ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "metadata = {\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"reference_audio\": ref_audio_path,\n",
    "    \"reference_duration_sec\": float(ref_duration),\n",
    "    \"reference_text\": ref_text,\n",
    "    \"asr_model\": asr_model_id,\n",
    "    \"device\": device,\n",
    "    \"generated_texts\": target_texts,\n",
    "    \"num_outputs\": len(target_texts),\n",
    "    \"sample_rate\": sample_rate,\n",
    "}\n",
    "\n",
    "metadata_path = output_dir / \"metadata.json\"\n",
    "with open(metadata_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metadata, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"âœ“ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜: {metadata_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆGoogle Colabç”¨ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Colabã§ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ZIPã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰\n",
    "try:\n",
    "    from google.colab import files\n",
    "    import zipfile\n",
    "    \n",
    "    # ZIPãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ\n",
    "    zip_path = \"qwen_voiceclone_outputs.zip\"\n",
    "    print(f\"ZIPãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆä¸­: {zip_path}\")\n",
    "    \n",
    "    with zipfile.ZipFile(zip_path, \"w\", zipfile.ZIP_DEFLATED) as zipf:\n",
    "        for file_path in output_dir.glob(\"*\"):\n",
    "            if file_path.is_file():\n",
    "                zipf.write(file_path, file_path.name)\n",
    "                print(f\"  è¿½åŠ : {file_path.name}\")\n",
    "    \n",
    "    print(f\"âœ“ ZIPä½œæˆå®Œäº†\")\n",
    "    print(f\"ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’é–‹å§‹ã—ã¾ã™...\")\n",
    "    files.download(zip_path)\n",
    "    print(\"âœ“ ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å®Œäº†\")\n",
    "    \n",
    "except:\n",
    "    print(\"ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§ã¯ outputs/ ãƒ•ã‚©ãƒ«ãƒ€ã‚’ç¢ºèªã—ã¦ãã ã•ã„\")\n",
    "    print(f\"ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(list(output_dir.glob('*.wav')))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ã¾ã¨ã‚\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ä»¥ä¸‹ã‚’å®Ÿè£…ã—ã¾ã—ãŸ:\n",
    "\n",
    "1. **Qwen2-Audio ASR**: å‚ç…§éŸ³å£°ã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã¨è©±è€…ç‰¹å¾´ã‚’æŠ½å‡º\n",
    "2. **Speaker Embedding**: è©±è€…ã®å£°è³ªã‚’è¡¨ç¾ã™ã‚‹ãƒ™ã‚¯ãƒˆãƒ«ã‚’å–å¾—\n",
    "3. **Qwen-TTS/CosyVoice**: è©±è€…ç‰¹å¾´ã‚’æ¡ä»¶ã«æ–°ã—ã„ãƒ†ã‚­ã‚¹ãƒˆã‚’éŸ³å£°åŒ–\n",
    "4. **ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆå­¦ç¿’**: 5-30ç§’ã®å‚ç…§éŸ³å£°ã®ã¿ã§å£°ã‚’ã‚¯ãƒ­ãƒ¼ãƒ³\n",
    "\n",
    "### æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—\n",
    "- ã‚ˆã‚Šé•·ã„å‚ç…§éŸ³å£°ã§å“è³ªå‘ä¸Š\n",
    "- LoRAå­¦ç¿’ã§ç‰¹å®šè©±è€…ã«ç‰¹åŒ–\n",
    "- RVCçµ±åˆã§è³ªæ„Ÿå‘ä¸Š\n",
    "- ãƒãƒƒãƒå‡¦ç†ã®å®Ÿè£…"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
